{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch 深度学习框架\n",
    "# tensor 张量 pytorch中装载数据的基本单位 数据存储单元 就像np.ndarray\n",
    "#\n",
    "\n",
    "import torch\n",
    "data = torch.tensor([[1,2],[3,4]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.array([[1,2],[3,4]])\n",
    "data2 = torch.from_numpy(np_array)\n",
    "data2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#添加张量的方式\n",
    "#torch.tensor()\n",
    "#torch.from_numpy()\n",
    "#torch.ones_like(data,dtype = torch.float32)\n",
    "data3 = torch.ones_like(data2,dtype = torch.int32)\n",
    "data3\n",
    "#shape 默认dtype =  folat\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor  = torch.ones(shape)\n",
    "\n",
    "rand_tensor\n",
    "ones_tensor\n",
    "zeros_tensor\n",
    "\n",
    "# torch.rand() 均匀分布\n",
    "# torch.randn() 标准正态分布\n",
    "# torch.normal(mean,std,shape) 一般正态分布\n",
    "# torch.linspace(start,end,steps) 等差数列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#tenssor 属性\n",
    "tensor = torch.randn(2,2)\n",
    "print(tensor.shape)\n",
    "print(tensor.size())\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[ 0.2781, -2.6395],\n",
      "        [ 1.8954,  1.3800]])\n"
     ]
    }
   ],
   "source": [
    "#切换tensor运行 模型训练设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor = tensor.to(device)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row: tensor([0.3707, 0.0786, 0.2794, 0.6850])\n",
      "first column: tensor([0.3707, 0.0849, 0.9652, 0.1202])\n",
      "last column of all dimension: tensor([0.3707, 0.0849, 0.9652, 0.1202])\n",
      "tensor([[3.7067e-01, 1.0000e+00, 2.7942e-01, 6.8504e-01],\n",
      "        [8.4873e-02, 1.0000e+00, 1.4216e-01, 8.1704e-02],\n",
      "        [9.6516e-01, 1.0000e+00, 6.4281e-01, 7.2506e-01],\n",
      "        [1.2020e-01, 1.0000e+00, 7.2151e-04, 6.8370e-01]])\n",
      "torch.float32\n",
      "tensor([[[3.7067e-01, 1.0000e+00],\n",
      "         [2.7942e-01, 6.8504e-01]],\n",
      "\n",
      "        [[8.4873e-02, 1.0000e+00],\n",
      "         [1.4216e-01, 8.1704e-02]],\n",
      "\n",
      "        [[9.6516e-01, 1.0000e+00],\n",
      "         [6.4281e-01, 7.2506e-01]],\n",
      "\n",
      "        [[1.2020e-01, 1.0000e+00],\n",
      "         [7.2151e-04, 6.8370e-01]]])\n"
     ]
    }
   ],
   "source": [
    "#取tensor 切片\n",
    "tensor = torch.rand(4,4)\n",
    "\n",
    "print(\"first row:\",tensor[0,])\n",
    "print(\"first column:\",tensor[:,0])\n",
    "print(\"last column of all dimension:\",tensor[...,0])\n",
    "\n",
    "# tensor 特定位置数值替换\n",
    "tensor[:,1] = 1\n",
    "print(tensor)\n",
    "print(tensor.dtype)\n",
    "# tensor 改变形状\n",
    "print(tensor.reshape(4,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]) torch.float32 torch.Size([4, 2])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]) torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "#张量拼接 用列表[]包起来 torch.cat()被拼的维度相同可拼 torch.stack()所有维度相同可拼\n",
    "tensor = torch.ones(2,2)\n",
    "tensor1 = torch.cat([tensor,tensor],dim = 0)\n",
    "print(tensor1,tensor1.dtype,tensor1.shape)\n",
    "#\n",
    "tensor2 =torch.cat([tensor,tensor1],dim= 0)\n",
    "print(tensor2,tensor2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[  196.,  1024.,  2500.],\n",
      "        [ 1024.,  5929., 14884.],\n",
      "        [ 2500., 14884., 37636.]])\n",
      "tensor([[  196.,  1024.,  2500.],\n",
      "        [ 1024.,  5929., 14884.],\n",
      "        [ 2500., 14884., 37636.]])\n"
     ]
    }
   ],
   "source": [
    "#tensor 运算 @ and matmul()\n",
    "import torch\n",
    "tensor = torch.arange(1,10,dtype = torch.float32).reshape(3,3)\n",
    "\n",
    "res1 = tensor @ tensor.T\n",
    "res2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(res1)\n",
    "torch.matmul(tensor,tensor.T,out = y3)\n",
    "\n",
    "print(res1)\n",
    "print(res2)\n",
    "print(y3)\n",
    "\n",
    "#tensor 各元素对位相乘 * and mul()\n",
    "z1 = res1 * res2\n",
    "z2 = res1.mul(res2)\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0 <class 'float'>\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]] float32\n"
     ]
    }
   ],
   "source": [
    "# torch 中tensor 类型变为原始python类型.item() 或 numpy类型.numpy()\n",
    "import torch\n",
    "import numpy\n",
    "tensor = torch.arange(1,10,1,dtype = torch.float32).reshape(3,3)\n",
    "sum = tensor.sum()\n",
    "sum_item = sum.item()\n",
    "print(sum_item,type(sum_item))\n",
    "\n",
    "np_array = tensor.numpy()\n",
    "print(np_array,np_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_place 操作 一般不用 tensor.add_(1) 等价于 tensor += 5 tensor中每个元素加5\n",
    "# 造成计算图路径混淆 不利于求导反向传播和模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图 深度学习框架都是用计算图来实现前向传播 反向传播 梯度下降的\n",
    "#相当于一个模型参数等运算的流程图 路径\n",
    "#Pytorch的计算图是动态计算图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22013\\AppData\\Local\\Temp\\ipykernel_8792\\1518058132.py:12: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3729.)\n",
      "  res = torch.matmul(x.T, A) + torch.matmul(b,x) + c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用torchviz来可视化查看pytorch中运算的计算图\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "#定义矩阵A 向量b x 常数c \n",
    "A = torch.randn(10,10,requires_grad = True) # True表示需要对A求导计算梯度\n",
    "b = torch.randn(10,requires_grad = True)\n",
    "c = torch.randn(1,requires_grad = True)\n",
    "x = torch.randn(10,requires_grad = True)\n",
    "\n",
    "#计算 x.T @ A + b.T @ x + c\n",
    "res = torch.matmul(x.T, A) + torch.matmul(b,x) + c\n",
    "\n",
    "# 生成计算图节点并可视化展示\n",
    "dot = make_dot(res,params = {'A':A,'b':b,'c':c,'x':x})\n",
    "dot.render('expression',format = 'png',cleanup= True,view = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
